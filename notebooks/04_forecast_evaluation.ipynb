# notebooks/04_forecast_evaluation.ipynb

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ForecastEngine: Forecast Evaluation\n",
    "\n",
    "This notebook evaluates forecast quality, uncertainty quantification, and business impact."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from forecast_engine import ForecastEngine\n",
    "import yaml\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load ForecastEngine and Generate Forecasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load configuration\n",
    "try:\n",
    "    with open('../config/simple_config.yaml', 'r') as f:\n",
    "        config = yaml.safe_load(f)\nexcept:\n",
    "    config = {\n",
    "        'target_column': 'value',\n",
    "        'date_column': 'date',\n",
    "        'data_path': '../data/sample_data.csv'\n",
    "    }\n",
    "\n",
    "# Initialize and train ForecastEngine\n",
    "engine = ForecastEngine(config)\n",
    "\n",
    "print(\"Training ForecastEngine...\")\n",
    "engine.fit(\n",
    "    target_column=config['target_column'],\n",
    "    date_column=config['date_column']\n",
    ")\n",
    "\n",
    "print(\"ForecastEngine trained successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate forecasts with different horizons\n",
    "horizons = [7, 14, 30]\n",
    "confidence_levels = [0.1, 0.25, 0.5, 0.75, 0.9]\n",
    "\n",
    "forecasts = {}\n",
    "for horizon in horizons:\n",
    "    print(f\"Generating {horizon}-day forecast...\")\n",
    "    forecast_result = engine.predict(\n",
    "        horizon=horizon,\n",
    "        confidence_levels=confidence_levels,\n",
    "        include_explanation=True\n",
    "    )\n",
    "    forecasts[horizon] = forecast_result\n",
    "\n",
    "print(\"All forecasts generated!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Forecast Accuracy Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize forecasts for different horizons\n",
    "fig, axes = plt.subplots(len(horizons), 1, figsize=(15, 4*len(horizons)))\n",
    "if len(horizons) == 1:\n",
    "    axes = [axes]\n",
    "\n",
    "# Load actual data for comparison\n",
    "actual_data = pd.read_csv('../data/sample_data.csv')\n",
    "actual_data['date'] = pd.to_datetime(actual_data['date'])\n",
    "\n",
    "for i, horizon in enumerate(horizons):\n",
    "    forecast_result = forecasts[horizon]\n",
    "    \n",
    "    # Create future dates\n",
    "    last_date = actual_data['date'].max()\n",
    "    future_dates = pd.date_range(start=last_date + timedelta(days=1), periods=horizon, freq='D')\n",
    "    \n",
    "    # Plot historical data\n",
    "    axes[i].plot(actual_data['date'].tail(30), actual_data['value'].tail(30), \n",
    "                label='Historical', color='black', linewidth=2)\n",
    "    \n",
    "    # Plot forecast\n",
    "    axes[i].plot(future_dates, forecast_result['forecast'], \n",
    "                label='Forecast', color='blue', linewidth=2, marker='o')\n",
    "    \n",
    "    # Plot confidence intervals\n",
    "    if 'prediction_intervals' in forecast_result:\n",
    "        intervals = forecast_result['prediction_intervals']\n",
    "        \n",
    "        # 80% confidence interval\n",
    "        if 'lower_0.1' in intervals and 'upper_0.9' in intervals:\n",
    "            axes[i].fill_between(future_dates, intervals['lower_0.1'], intervals['upper_0.9'], \n",
    "                               alpha=0.2, color='blue', label='80% Confidence')\n",
    "        \n",
    "        # 50% confidence interval\n",
    "        if 'lower_0.25' in intervals and 'upper_0.75' in intervals:\n",
    "            axes[i].fill_between(future_dates, intervals['lower_0.25'], intervals['upper_0.75'], \n",
    "                               alpha=0.3, color='blue', label='50% Confidence')\n",
    "    \n",
    "    axes[i].set_title(f'{horizon}-Day Forecast with Confidence Intervals')\n",
    "    axes[i].set_xlabel('Date')\n",
    "    axes[i].set_ylabel('Value')\n",
    "    axes[i].legend()\n",
    "    axes[i].grid(True, alpha=0.3)\n",
    "    axes[i].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Uncertainty Quantification Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze prediction intervals\n",
    "def analyze_prediction_intervals(forecast_result, horizon):\n",
    "    \"\"\"Analyze the quality of prediction intervals\"\"\"\n",
    "    forecast = np.array(forecast_result['forecast'])\n",
    "    intervals = forecast_result.get('prediction_intervals', {})\n",
    "    \n",
    "    analysis = {\n",
    "        'horizon': horizon,\n",
    "        'mean_forecast': np.mean(forecast),\n",
    "        'forecast_trend': (forecast[-1] - forecast[0]) / len(forecast) if len(forecast) > 1 else 0\n",
    "    }\n",
    "    \n",
    "    # Calculate interval widths\n",
    "    for level in confidence_levels:\n",
    "        lower_key = f'lower_{level}'\n",
    "        upper_key = f'upper_{level}'\n",
    "        \n",
    "        if lower_key in intervals and upper_key in intervals:\n",
    "            lower = np.array(intervals[lower_key])\n",
    "            upper = np.array(intervals[upper_key])\n",
    "            width = upper - lower\n",
    "            \n",
    "            analysis[f'interval_width_{level}'] = np.mean(width)\n",
    "            analysis[f'relative_width_{level}'] = np.mean(width / forecast) * 100\n",
    "    \n",
    "    return analysis\n",
    "\n",
    "# Analyze all forecasts\n",
    "interval_analysis = []\n",
    "for horizon in horizons:\n",
    "    analysis = analyze_prediction_intervals(forecasts[horizon], horizon)\n",
    "    interval_analysis.append(analysis)\n",
    "\n",
    "interval_df = pd.DataFrame(interval_analysis)\n",
    "print(\"=== PREDICTION INTERVAL ANALYSIS ===\")\n",
    "print(interval_df.round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize uncertainty by horizon\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Interval width by horizon\n",
    "width_cols = [col for col in interval_df.columns if 'interval_width_' in col]\n",
    "if width_cols:\n",
    "    for col in width_cols[:3]:  # Show first 3 confidence levels\n",
    "        level = col.split('_')[-1]\n",
    "        axes[0].plot(interval_df['horizon'], interval_df[col], \n",
    "                    marker='o', label=f'{float(level)*100:.0f}% Confidence')\n",
    "    \n",
    "    axes[0].set_title('Prediction Interval Width by Horizon')\n",
    "    axes[0].set_xlabel('Forecast Horizon (days)')\n",
    "    axes[0].set_ylabel('Interval Width')\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Relative width by horizon\n",
    "rel_width_cols = [col for col in interval_df.columns if 'relative_width_' in col]\n",
    "if rel_width_cols:\n",
    "    for col in rel_width_cols[:3]:\n",
    "        level = col.split('_')[-1]\n",
    "        axes[1].plot(interval_df['horizon'], interval_df[col], \n",
    "                    marker='s', label=f'{float(level)*100:.0f}% Confidence')\n",
    "    \n",
    "    axes[1].set_title('Relative Prediction Interval Width by Horizon')\n",
    "    axes[1].set_xlabel('Forecast Horizon (days)')\n",
    "    axes[1].set_ylabel('Relative Width (%)')\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Explainability Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze explanations from forecasts\n",
    "def analyze_explanations(forecast_result, horizon):\n",
    "    \"\"\"Extract and analyze forecast explanations\"\"\"\n",
    "    explanations = forecast_result.get('explanations', {})\n",
    "    \n",
    "    if not explanations:\n",
    "        return None\n",
    "    \n",
    "    analysis = {'horizon': horizon}\n",
    "    \n",
    "    # Feature importance\n",
    "    feature_importance = explanations.get('feature_importance', {})\n",
    "    top_drivers = feature_importance.get('top_drivers', {})\n",
    "    \n",
    "    if top_drivers:\n",
    "        # Get top 3 features\n",
    "        sorted_features = sorted(top_drivers.items(), key=lambda x: x[1], reverse=True)[:3]\n",
    "        for i, (feature, importance) in enumerate(sorted_features):\n",
    "            analysis[f'top_feature_{i+1}'] = feature\n",
    "            analysis[f'top_importance_{i+1}'] = importance\n",
    "    \n",
    "    # Business insights\n",
    "    insights = explanations.get('business_insights', [])\n",
    "    analysis['num_insights'] = len(insights)\n",
    "    analysis['insights'] = '; '.join(insights[:2])  # First 2 insights\n",
    "    \n",
    "    # Confidence factors\n",
    "    confidence = explanations.get('confidence_factors', {})\n",
    "    analysis['model_agreement'] = confidence.get('model_agreement', 0)\n",
    "    analysis['data_quality'] = confidence.get('data_quality', 0)\n",
    "    \n",
    "    return analysis\n",
    "\n",
    "# Analyze explanations for all horizons\n",
    "explanation_analysis = []\n",
    "for horizon in horizons:\n",
    "    analysis = analyze_explanations(forecasts[horizon], horizon)\n",
    "    if analysis:\n",
    "        explanation_analysis.append(analysis)\n",
    "\n",
    "if explanation_analysis:\n",
    "    explanation_df = pd.DataFrame(explanation_analysis)\n",
    "    print(\"=== FORECAST EXPLANATIONS ANALYSIS ===\")\n",
    "    \n",
    "    # Show feature importance\n",
    "    feature_cols = [col for col in explanation_df.columns if 'top_feature_' in col]\n",
    "    importance_cols = [col for col in explanation_df.columns if 'top_importance_' in col]\n",
    "    \n",
    "    if feature_cols and importance_cols:\n",
    "        print(\"\\nTop Features by Horizon:\")\n",
    "        for _, row in explanation_df.iterrows():\n",
    "            horizon = row['horizon']\n",
    "            print(f\"\\n{horizon}-day forecast:\")\n",
    "            for i in range(1, 4):\n",
    "                feature_col = f'top_feature_{i}'\n",
    "                importance_col = f'top_importance_{i}'\n",
    "                if feature_col in row and importance_col in row:\n",
    "                    if pd.notna(row[feature_col]):\n",
    "                        print(f\"  {i}. {row[feature_col]}: {row[importance_col]:.3f}\")\n",
    "    \n",
    "    # Show confidence metrics\n",
    "    if 'model_agreement' in explanation_df.columns:\n",
    "        print(\"\\nConfidence Metrics:\")\n",
    "        print(explanation_df[['horizon', 'model_agreement', 'data_quality']].round(3))\n",
    "    \n",
    "    # Show business insights\n",
    "    if 'insights' in explanation_df.columns:\n",
    "        print(\"\\nBusiness Insights:\")\n",
    "        for _, row in explanation_df.iterrows():\n",
    "            if pd.notna(row['insights']):\n",
    "                print(f\"{row['horizon']}-day: {row['insights']}\")\nelse:\n",
    "    print(\"No explanations available in forecast results\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Business Impact Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate business impact of forecasts\n",
    "def calculate_business_impact(forecast_result, horizon, unit_cost=10, unit_price=15):\n",
    "    \"\"\"Calculate potential business impact of forecast accuracy\"\"\"\n",
    "    forecast = np.array(forecast_result['forecast'])\n",
    "    intervals = forecast_result.get('prediction_intervals', {})\n",
    "    \n",
    "    # Calculate potential revenue\n",
    "    expected_revenue = np.sum(forecast) * unit_price\n",
    "    \n",
    "    # Calculate inventory costs (assuming we stock for upper confidence level)\n",
    "    if 'upper_0.9' in intervals:\n",
    "        safety_stock = np.sum(intervals['upper_0.9']) - np.sum(forecast)\n",
    "        inventory_cost = safety_stock * unit_cost\n",
    "    else:\n",
    "        inventory_cost = 0\n",
    "    \n",
    "    # Calculate stockout risk (if demand exceeds forecast)\n",
    "    if 'lower_0.1' in intervals:\n",
    "        potential_stockout = max(0, np.sum(forecast) - np.sum(intervals['lower_0.1']))\n",
    "        stockout_cost = potential_stockout * (unit_price - unit_cost)  # Lost profit\n",
    "    else:\n",
    "        stockout_cost = 0\n",
    "    \n",
    "    return {\n",
    "        'horizon': horizon,\n",
    "        'expected_revenue': expected_revenue,\n",
    "        'inventory_cost': inventory_cost,\n",
    "        'stockout_risk': stockout_cost,\n",
    "        'net_impact': expected_revenue - inventory_cost - stockout_cost,\n",
    "        'forecast_sum': np.sum(forecast),\n",
    "        'forecast_mean': np.mean(forecast)\n",
    "    }\n",
    "\n",
    "# Calculate business impact for all horizons\n",
    "business_impacts = []\n",
    "for horizon in horizons:\n",
    "    impact = calculate_business_impact(forecasts[horizon], horizon)\n",
    "    business_impacts.append(impact)\n",
    "\n",
    "business_df = pd.DataFrame(business_impacts)\n",
    "print(\"=== BUSINESS IMPACT ANALYSIS ===\")\n",
    "print(business_df.round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize business impact\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Expected revenue by horizon\n",
    "axes[0,0].bar(business_df['horizon'], business_df['expected_revenue'], color='green', alpha=0.7)\n",
    "axes[0,0].set_title('Expected Revenue by Forecast Horizon')\n",
    "axes[0,0].set_xlabel('Horizon (days)')\n",
    "axes[0,0].set_ylabel('Revenue ($)')\n",
    "\n",
    "# Cost breakdown\n",
    "width = 0.35\n",
    "x = np.arange(len(business_df))\n",
    "axes[0,1].bar(x - width/2, business_df['inventory_cost'], width, label='Inventory Cost', color='orange')\n",
    "axes[0,1].bar(x + width/2, business_df['stockout_risk'], width, label='Stockout Risk', color='red')\n",
    "axes[0,1].set_title('Cost Analysis by Horizon')\n",
    "axes[0,1].set_xlabel('Horizon (days)')\n",
    "axes[0,1].set_ylabel('Cost ($)')\n",
    "axes[0,1].set_xticks(x)\n",
    "axes[0,1].set_xticklabels(business_df['horizon'])\n",
    "axes[0,1].legend()\n",
    "\n",
    "# Net impact\n",
    "colors = ['green' if x > 0 else 'red' for x in business_df['net_impact']]\n",
    "axes[1,0].bar(business_df['horizon'], business_df['net_impact'], color=colors, alpha=0.7)\n",
    "axes[1,0].set_title('Net Business Impact by Horizon')\n",
    "axes[1,0].set_xlabel('Horizon (days)')\n",
    "axes[1,0].set_ylabel('Net Impact ($)')\n",
    "axes[1,0].axhline(y=0, color='black', linestyle='--', alpha=0.5)\n",
    "\n",
    "# Forecast values\n",
    "axes[1,1].plot(business_df['horizon'], business_df['forecast_sum'], marker='o', linewidth=2, color='blue')\n",
    "axes[1,1].set_title('Total Forecast Value by Horizon')\n",
    "axes[1,1].set_xlabel('Horizon (days)')\n",
    "axes[1,1].set_ylabel('Forecast Sum')\n",
    "axes[1,1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Forecast Quality Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate comprehensive forecast quality report\n",
    "print(\"=== FORECASTENGINE EVALUATION SUMMARY ===\")\n",
    "print(f\"Evaluation Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(f\"Horizons Tested: {horizons}\")\n",
    "print(f\"Confidence Levels: {[f'{int(x*100)}%' for x in confidence_levels]}\")\n",
    "\n",
    "print(\"\\n=== FORECAST ACCURACY ===\")\n",
    "for horizon in horizons:\n",
    "    forecast_values = forecasts[horizon]['forecast']\n",
    "    print(f\"{horizon}-day forecast:\")\n",
    "    print(f\"  Mean value: {np.mean(forecast_values):.1f}\")\n",
    "    print(f\"  Value range: {np.min(forecast_values):.1f} - {np.max(forecast_values):.1f}\")\n",
    "    print(f\"  Trend: {((forecast_values[-1] - forecast_values[0]) / len(forecast_values)):.2f} per day\")\n",
    "\n",
    "print(\"\\n=== UNCERTAINTY QUANTIFICATION ===\")\n",
    "for _, row in interval_df.iterrows():\n",
    "    horizon = int(row['horizon'])\n",
    "    print(f\"{horizon}-day forecast uncertainty:\")\n",
    "    \n",
    "    # Show relative widths for key confidence levels\n",
    "    key_levels = [0.5, 0.75, 0.9]\n",
    "    for level in key_levels:\n",
    "        col_name = f'relative_width_{level}'\n",
    "        if col_name in row and pd.notna(row[col_name]):\n",
    "            print(f\"  {int(level*100)}% confidence interval: ±{row[col_name]:.1f}%\")\n",
    "\n",
    "print(\"\\n=== BUSINESS IMPACT ===\")\n",
    "best_horizon = business_df.loc[business_df['net_impact'].idxmax(), 'horizon']\n",
    "best_impact = business_df['net_impact'].max()\n",
    "total_revenue = business_df['expected_revenue'].sum()\n",
    "total_costs = business_df['inventory_cost'].sum() + business_df['stockout_risk'].sum()\n",
    "\n",
    "print(f\"Best performing horizon: {best_horizon} days (${best_impact:.0f} net impact)\")\n",
    "print(f\"Total expected revenue: ${total_revenue:.0f}\")\n",
    "print(f\"Total risk costs: ${total_costs:.0f}\")\n",
    "print(f\"Overall efficiency: {((total_revenue - total_costs) / total_revenue * 100):.1f}%\")\n",
    "\n",
    "print(\"\\n=== RECOMMENDATIONS ===\")\n",
    "print(f\"• Use {best_horizon}-day forecasts for optimal business impact\")\n",
    "print(f\"• Monitor forecast accuracy - retrain if error increases significantly\")\n",
    "print(f\"• Consider inventory optimization based on 90% confidence intervals\")\n",
    "print(f\"• Review forecasts weekly and adjust business plans accordingly\")\n",
    "\n",
    "if explanation_analysis:\n",
    "    print(\"\\n=== MODEL INSIGHTS ===\")\n",
    "    avg_agreement = np.mean([x.get('model_agreement', 0) for x in explanation_analysis])\n",
    "    avg_quality = np.mean([x.get('data_quality', 0) for x in explanation_analysis])\n",
    "    print(f\"Average model agreement: {avg_agreement:.1%}\")\n",
    "    print(f\"Average data quality: {avg_quality:.1%}\")\n",
    "    print(f\"Model confidence: {'High' if avg_agreement > 0.8 else 'Medium' if avg_agreement > 0.6 else 'Low'}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}